{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTImageProcessor, TrainingArguments, Trainer, YolosForObjectDetection\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19915e1dc124d06863cc1d7151dc4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "ds_location = Path.cwd() / \"DatasetOriginal\"\n",
    "# print(ds_location)\n",
    "csv_location = ds_location / \"metadata.csv\"\n",
    "# print(str(csv_location))\n",
    "orig_dataset = load_dataset(\"csv\", data_files=str(csv_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file_name', 'image_id', 'width', 'height', 'objects'],\n",
      "        num_rows: 12101\n",
      "    })\n",
      "})\n",
      "dict_keys(['file_name', 'image_id', 'width', 'height', 'objects'])\n"
     ]
    }
   ],
   "source": [
    "print(orig_dataset)\n",
    "print(orig_dataset[\"train\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = orig_dataset[\"train\"].train_test_split(test_size=0.3, seed=5)\n",
    "wildlife_train_ds = train_test_split[\"train\"]\n",
    "wildlife_test_ds = train_test_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking...\n",
      "Dataset({\n",
      "    features: ['file_name', 'image_id', 'width', 'height', 'objects'],\n",
      "    num_rows: 8470\n",
      "})\n",
      "Dataset({\n",
      "    features: ['file_name', 'image_id', 'width', 'height', 'objects'],\n",
      "    num_rows: 3631\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"checking...\")\n",
    "print(wildlife_train_ds)\n",
    "print(wildlife_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking...\n",
      "type of the above -> <class 'str'>\n",
      "category of the above -> raccoon\n"
     ]
    }
   ],
   "source": [
    "print(\"checking...\")\n",
    "#! the following actually returns a <string>\n",
    "test_sample1 = wildlife_train_ds[10].get(\"objects\")\n",
    "# print(test_sample1)\n",
    "match_str = \"\\'category\\'\"\n",
    "\n",
    "print(f\"type of the above -> {type(test_sample1)}\")\n",
    "#! +13 for the starting index of actual category\n",
    "#! -2 for the ending idx\n",
    "start_idx = test_sample1.find(match_str) + 13\n",
    "category1 = test_sample1[start_idx: -2]\n",
    "print(f\"category of the above -> {category1}\")\n",
    "\n",
    "# print(wildlife_test_ds[10].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(example):\n",
    "    file_path = ds_location / example[\"file_name\"]  # Get the file path\n",
    "    image = Image.open(file_path)  # Load the image as a PIL Image\n",
    "    \n",
    "    test_sample1 = example['objects']\n",
    "    start_idx = test_sample1.find(match_str) + 13\n",
    "    category1 = test_sample1[start_idx: -2]\n",
    "    \n",
    "    return {\n",
    "        \"file_name\": example[\"file_name\"],\n",
    "        \"image_id\": example[\"image_id\"],\n",
    "        \"width\": example[\"width\"],\n",
    "        \"height\": example[\"height\"],\n",
    "        \"image\": image,\n",
    "        \"labels\": category1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dfaad8b24247b3b82eac27b72d96dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_name', 'image_id', 'width', 'height', 'objects', 'image', 'labels'],\n",
      "    num_rows: 8470\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Use the map function to add the \"image\" field\n",
    "updated_train_ds = wildlife_train_ds.map(load_image)\n",
    "print(updated_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef52d2641e934de48141ba4ed3643af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3631 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_name', 'image_id', 'width', 'height', 'objects', 'image', 'labels'],\n",
      "    num_rows: 3631\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "updated_test_ds = wildlife_test_ds.map(load_image)\n",
    "print(updated_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del wildlife_train_ds\n",
    "del wildlife_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_name', 'image_id', 'width', 'height', 'image', 'labels'],\n",
      "    num_rows: 8470\n",
      "})\n",
      "dict_keys(['file_name', 'image_id', 'width', 'height', 'image', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "updated_train_ds = updated_train_ds.remove_columns([\"objects\"])\n",
    "print(updated_train_ds)\n",
    "print(updated_train_ds[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_name', 'image_id', 'width', 'height', 'image', 'labels'],\n",
      "    num_rows: 3631\n",
      "})\n",
      "dict_keys(['file_name', 'image_id', 'width', 'height', 'image', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "updated_test_ds = updated_test_ds.remove_columns([\"objects\"])\n",
    "print(updated_test_ds)\n",
    "print(updated_test_ds[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = DatasetDict({\n",
    "    \"train\": updated_train_ds,\n",
    "    \"test\": updated_test_ds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file_name', 'image_id', 'width', 'height', 'image', 'labels'],\n",
      "        num_rows: 8470\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['file_name', 'image_id', 'width', 'height', 'image', 'labels'],\n",
      "        num_rows: 3631\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['file_name', 'image_id', 'width', 'height', 'image', 'labels'],\n",
      "    num_rows: 8470\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(updated_dataset)\n",
    "print(updated_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['file_name', 'image_id', 'width', 'height', 'image', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(updated_dataset[\"train\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2c0f0a73c043e3b2d08c81dd5dfe5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5375991dd86c4387881e046e08586c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d3f8e2157f44a596b9402b3764c41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56481f4a4f54c2da340d5625c5214a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f695128d7ec1445a8c08006951091fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3131a9ee0d4c7d856b3e9b1da33671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1b374eca484449a32ad48bea893b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d386537b00046f1bab1d7e37c005a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dfa471cdd24e49a18df9f3a02ea35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a8dc642b7f4bc29f0cfe518f71ebe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1411 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37311bf62851413ba105af46ac4b8f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf0a7b2def44bf38a61b8805b2254ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1411 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40852f56f33408aa3e23b27710718b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a8ca35ad7540c0b7ebd8486a5576dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd52faeb9eb24b20b0516d6b133f7e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1816 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ee65d899f645458261b3374cf2db3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83cb265f79fa40048557d6c3a124dc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b281e52438b04747a3aba05a88e427a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/SeaSponge/wildme10_classify/commit/d0b6e31c8f95c8267b7622bd1d725a3282e8a54f', commit_message='Upload dataset', commit_description='', oid='d0b6e31c8f95c8267b7622bd1d725a3282e8a54f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/SeaSponge/wildme10_classify', endpoint='https://huggingface.co', repo_type='dataset', repo_id='SeaSponge/wildme10_classify'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_dataset.push_to_hub(\"SeaSponge/wildme10_classify\",\n",
    "                             max_shard_size=\"1GB\",\n",
    "                             num_shards={\"train\": 6, \"test\": 2})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
