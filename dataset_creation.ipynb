{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f855bf4-c42e-4ca5-aac9-d2b99b1ed3af",
   "metadata": {},
   "source": [
    "### Part 1. Preprocessing and selecting images from hyena and leopard dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a4f54e-f2a7-4512-b427-a9b8893fda50",
   "metadata": {},
   "source": [
    "We want pictures that are sufficiently bright, that the animal takes a sufficiently large area in the picture, and that it is not grayscale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd6284-b3cb-4e3e-b5e4-1841b15c8d55",
   "metadata": {},
   "source": [
    "#### Step 1: Selecting large-area-of-animal pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f0454c9-556b-4464-b0b5-5659ade77e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import ast\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67967a19-52a6-4dfa-b941-8514b2d91985",
   "metadata": {},
   "source": [
    "Read the file containing areas of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d4309f-b2c2-4b54-a520-c6a7dcba16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "leo_hye_df = pd.read_csv('C:/mixed/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d85016d0-5153-463f-b93d-eda8d423c2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>bboxes</th>\n",
       "      <th>areas</th>\n",
       "      <th>normalized_bboxes</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000000001.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>1800</td>\n",
       "      <td>[[163.02083333333334, 411.9791666666667, 2161....</td>\n",
       "      <td>[2674804.6875]</td>\n",
       "      <td>[[0.06792534722222222, 0.22887731481481483, 0....</td>\n",
       "      <td>[0]</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000000002.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>1800</td>\n",
       "      <td>[[448.43750000000006, 301.0416666666667, 1794....</td>\n",
       "      <td>[1952204.0473090282]</td>\n",
       "      <td>[[0.18684895833333337, 0.16724537037037038, 0....</td>\n",
       "      <td>[0]</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000000003.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>1800</td>\n",
       "      <td>[[476.0416666666667, 628.6458333333334, 1743.7...</td>\n",
       "      <td>[1964443.3593750002]</td>\n",
       "      <td>[[0.19835069444444445, 0.34924768518518523, 0....</td>\n",
       "      <td>[0]</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000000004.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>1800</td>\n",
       "      <td>[[206.77083333333334, 255.20833333333334, 2193...</td>\n",
       "      <td>[3080801.595052084]</td>\n",
       "      <td>[[0.0861545138888889, 0.1417824074074074, 0.91...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000000005.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>1800</td>\n",
       "      <td>[[296.3541666666667, 633.8541666666667, 1947.9...</td>\n",
       "      <td>[1867768.012152778]</td>\n",
       "      <td>[[0.12348090277777779, 0.3521412037037037, 0.8...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>1000000003099.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>1600</td>\n",
       "      <td>[[754.7945205479451, 498.63013698630135, 764.3...</td>\n",
       "      <td>[520932.6327641209]</td>\n",
       "      <td>[[0.31449771689497713, 0.3116438356164383, 0.3...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>hyena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>1000000003100.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>1600</td>\n",
       "      <td>[[612.3287671232877, 503.42465753424653, 1026....</td>\n",
       "      <td>[754059.861137174]</td>\n",
       "      <td>[[0.2551369863013699, 0.3146404109589041, 0.42...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>hyena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>1000000003101.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>2225</td>\n",
       "      <td>[[0.0, 202.02020202020202, 2338.5858585858587,...</td>\n",
       "      <td>[4422053.259871442]</td>\n",
       "      <td>[[0, 0.09079559641357395, 0.9744107744107744, ...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>hyena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>1000000003102.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>1600</td>\n",
       "      <td>[[980.1369863013698, 276.027397260274, 1266.43...</td>\n",
       "      <td>[938552.2612122349]</td>\n",
       "      <td>[[0.4083904109589041, 0.17251712328767124, 0.5...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>hyena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>1000000003103.jpg</td>\n",
       "      <td>2400</td>\n",
       "      <td>1800</td>\n",
       "      <td>[[1448.4375, 717.1875, 651.5625, 397.265625]]</td>\n",
       "      <td>[258843.3837890625]</td>\n",
       "      <td>[[0.603515625, 0.3984375, 0.271484375, 0.22070...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>hyena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9897 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name  width  height  \\\n",
       "0      000000000001.jpg   2400    1800   \n",
       "1      000000000002.jpg   2400    1800   \n",
       "2      000000000003.jpg   2400    1800   \n",
       "3      000000000004.jpg   2400    1800   \n",
       "4      000000000005.jpg   2400    1800   \n",
       "...                 ...    ...     ...   \n",
       "9892  1000000003099.jpg   2400    1600   \n",
       "9893  1000000003100.jpg   2400    1600   \n",
       "9894  1000000003101.jpg   2400    2225   \n",
       "9895  1000000003102.jpg   2400    1600   \n",
       "9896  1000000003103.jpg   2400    1800   \n",
       "\n",
       "                                                 bboxes                 areas  \\\n",
       "0     [[163.02083333333334, 411.9791666666667, 2161....        [2674804.6875]   \n",
       "1     [[448.43750000000006, 301.0416666666667, 1794....  [1952204.0473090282]   \n",
       "2     [[476.0416666666667, 628.6458333333334, 1743.7...  [1964443.3593750002]   \n",
       "3     [[206.77083333333334, 255.20833333333334, 2193...   [3080801.595052084]   \n",
       "4     [[296.3541666666667, 633.8541666666667, 1947.9...   [1867768.012152778]   \n",
       "...                                                 ...                   ...   \n",
       "9892  [[754.7945205479451, 498.63013698630135, 764.3...   [520932.6327641209]   \n",
       "9893  [[612.3287671232877, 503.42465753424653, 1026....    [754059.861137174]   \n",
       "9894  [[0.0, 202.02020202020202, 2338.5858585858587,...   [4422053.259871442]   \n",
       "9895  [[980.1369863013698, 276.027397260274, 1266.43...   [938552.2612122349]   \n",
       "9896      [[1448.4375, 717.1875, 651.5625, 397.265625]]   [258843.3837890625]   \n",
       "\n",
       "                                      normalized_bboxes category    label  \n",
       "0     [[0.06792534722222222, 0.22887731481481483, 0....      [0]  leopard  \n",
       "1     [[0.18684895833333337, 0.16724537037037038, 0....      [0]  leopard  \n",
       "2     [[0.19835069444444445, 0.34924768518518523, 0....      [0]  leopard  \n",
       "3     [[0.0861545138888889, 0.1417824074074074, 0.91...      [0]  leopard  \n",
       "4     [[0.12348090277777779, 0.3521412037037037, 0.8...      [0]  leopard  \n",
       "...                                                 ...      ...      ...  \n",
       "9892  [[0.31449771689497713, 0.3116438356164383, 0.3...      [1]    hyena  \n",
       "9893  [[0.2551369863013699, 0.3146404109589041, 0.42...      [1]    hyena  \n",
       "9894  [[0, 0.09079559641357395, 0.9744107744107744, ...      [1]    hyena  \n",
       "9895  [[0.4083904109589041, 0.17251712328767124, 0.5...      [1]    hyena  \n",
       "9896  [[0.603515625, 0.3984375, 0.271484375, 0.22070...      [1]    hyena  \n",
       "\n",
       "[9897 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leo_hye_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c70f2e-8aba-4db7-9e6f-57efd617f8a1",
   "metadata": {},
   "source": [
    "collect all the areas and find the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe280da7-85e4-4087-9116-f3ece0959ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_list = []\n",
    "for i in range(len(leo_hye_df)):\n",
    "    temp = ast.literal_eval(leo_hye_df.loc[i,'areas'])\n",
    "    area = temp[0]\n",
    "    area_list.append(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "961d24d6-7c5d-4567-b9bd-72fa210ab8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772578.125 1265025.384172909\n"
     ]
    }
   ],
   "source": [
    "median = statistics.median(area_list)\n",
    "mean = statistics.mean(area_list)\n",
    "print(median, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b079a18-49aa-453d-83a1-539d6db7466d",
   "metadata": {},
   "source": [
    "After looking at the pictures around this region, I decide to use 750000 as my threshold of selecting pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f76956a-14fd-4d5d-8293-95fa4a8aa00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'C:/mixed'\n",
    "output_path = 'C:/mixed_large'\n",
    "for i in range(len(area_list)):\n",
    "    if area_list[i] > 750000:\n",
    "        image_name = leo_hye_df.loc[i,'file_name']\n",
    "        shutil.copy(os.path.join(input_path,image_name),os.path.join(output_path,image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d342f17-9434-403d-b17e-d5d88a7362a5",
   "metadata": {},
   "source": [
    "Through this process, we obtain 5016 pictures out of 9200."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361d2b1-ea92-4cf5-b791-b6c29851109c",
   "metadata": {},
   "source": [
    "#### Step 2: Separate the grayscale pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31575d9e-9d65-429f-812d-fc9bdb7ae74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grayscale(image_path, threshold=0.95):\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Convert to RGB (if the image is in a different mode)\n",
    "    img = img.convert('RGB')\n",
    "    \n",
    "    # Convert image to numpy array for easy manipulation\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Calculate the number of pixels that are grayscale\n",
    "    grayscale_count = 0\n",
    "    total_pixels = img_array.shape[0] * img_array.shape[1]\n",
    "    \n",
    "    for row in img_array:\n",
    "        for pixel in row:\n",
    "            r, g, b = pixel\n",
    "            # Check if the pixel is grayscale (i.e., r == g == b)\n",
    "            if r == g == b:\n",
    "                grayscale_count += 1\n",
    "    \n",
    "    # Calculate the proportion of grayscale pixels\n",
    "    grayscale_ratio = grayscale_count / total_pixels\n",
    "    \n",
    "    # Check if the grayscale ratio is above the threshold\n",
    "    return grayscale_ratio >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e788999d-6cae-41c2-a25f-885ce00ae050",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m image_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(image_dir)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m image_list:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_grayscale(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, image)):\n\u001b[0;32m      7\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mcopy(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir,image),os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_path_gray,image))\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[20], line 19\u001b[0m, in \u001b[0;36mis_grayscale\u001b[1;34m(image_path, threshold)\u001b[0m\n\u001b[0;32m     17\u001b[0m         r, g, b \u001b[38;5;241m=\u001b[39m pixel\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# Check if the pixel is grayscale (i.e., r == g == b)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;241m==\u001b[39m g \u001b[38;5;241m==\u001b[39m b:\n\u001b[0;32m     20\u001b[0m             grayscale_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate the proportion of grayscale pixels\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_dir = 'C:/mixed_large'\n",
    "output_path_gray = 'C:/mixed_large_gray'\n",
    "output_path_color = 'C:/mixed_large_color'\n",
    "image_list = os.listdir(image_dir)\n",
    "for image in image_list:\n",
    "    if is_grayscale(os.path.join(image_dir, image)):\n",
    "        shutil.copy(os.path.join(image_dir,image),os.path.join(output_path_gray,image))\n",
    "    else:\n",
    "        shutil.copy(os.path.join(image_dir,image),os.path.join(output_path_color,image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d21b68-afa3-45e3-b734-476f39d4bc02",
   "metadata": {},
   "source": [
    "It turned out to be too time-consuming, so I ended it and manually separated the pictures (tears). There are 657 grayscale pictures in total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46372c-6c4a-4a7a-a45f-ea17340a5780",
   "metadata": {},
   "source": [
    "#### Step 3: Separate the extremely dark pictures, relatively dark pictures, and sufficiently bright pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca674821-dfd1-4d4c-95f7-fdc05355a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_brightness(image):\n",
    "    # Convert image to grayscale\n",
    "    grayscale_image = image.convert('L')\n",
    "\n",
    "    # Get pixel values as a numpy array\n",
    "    pixels = np.array(grayscale_image)\n",
    "\n",
    "    # Calculate mean pixel value\n",
    "    mean_brightness = np.mean(pixels)\n",
    "\n",
    "    return mean_brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62ac0ca9-7b37-4501-9934-d01a4b02591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'C:/mixed_large'\n",
    "output_path_vd = 'C:/mixed_large_verydark'\n",
    "output_path_d = 'C:/mixed_large_dark'\n",
    "out_path_b = 'C:/mixed_large_bright'\n",
    "image_name_list = os.listdir(input_path)\n",
    "for image_name in image_name_list:\n",
    "    image = Image.open(os.path.join(input_path,image_name))\n",
    "    width,height = image.size\n",
    "    resized_image = image.resize((int(0.3*width),int(0.3*height)))\n",
    "    if calculate_brightness(resized_image) <= 20:\n",
    "        if image_name[0] == '0':\n",
    "            image_name_new = '9' + '0'*3 + image_name[-8:]\n",
    "            resized_image.save(os.path.join(output_path_vd,image_name_new))\n",
    "        else:\n",
    "            image_name_new = '10' + '0'*3 + image_name[-8:]\n",
    "            resized_image.save(os.path.join(output_path_vd,image_name_new))\n",
    "    elif calculate_brightness(resized_image) <= 70:\n",
    "        if image_name[0] == '0':\n",
    "            image_name_new = '9' + '0'*3 + image_name[-8:]\n",
    "            resized_image.save(os.path.join(output_path_d,image_name_new))\n",
    "        else:\n",
    "            image_name_new = '10' + '0'*3 + image_name[-8:]\n",
    "            resized_image.save(os.path.join(output_path_d,image_name_new))\n",
    "    else:\n",
    "        if image_name[0] == '0':\n",
    "            image_name_new = '9' + '0'*3 + image_name[-8:]\n",
    "            resized_image.save(os.path.join(out_path_b,image_name_new))\n",
    "        else:\n",
    "            image_name_new = '10' + '0'*3 + image_name[-8:]\n",
    "            resized_image.save(os.path.join(out_path_b,image_name_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a9347-f252-4d6f-95cc-7e9660769bdc",
   "metadata": {},
   "source": [
    "### Part 2. Separate the general animal dataset for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da2eeb4-81c4-420c-843a-39939ed38278",
   "metadata": {},
   "source": [
    "#### Step 1. Separate the animal datasets into original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065832f-018b-418e-9248-807d454cd4d9",
   "metadata": {},
   "source": [
    "The fox dataset contains dark images with very poor quality. We first separate them and get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bce37062-4528-4c73-8834-6c3f1c1f25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'C:/Users/leiyi/OneDrive/Desktop/Dataset/fox'\n",
    "output_path = 'C:/Users/leiyi/OneDrive/Desktop/Dataset/red_fox'\n",
    "image_list = os.listdir(image_dir)\n",
    "for image_name in image_list:\n",
    "    image = Image.open(os.path.join(image_dir,image_name))\n",
    "    if calculate_brightness(image) > 45:\n",
    "        image.save(os.path.join(output_path,image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04d796-6ef9-47bd-b777-326fe7abd6fb",
   "metadata": {},
   "source": [
    "Now, we separate these images according to a 0.6:0.1:0.1:0.1:0.1 ratio. They will separately be the set of:\n",
    "1) well-illuminated pictures\n",
    "2) under-exposed pictures\n",
    "3) night-setting pictures\n",
    "4) extremely dark pictures\n",
    "5) grayscale pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfdb1106-e24a-4534-b3ba-2391094f03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_by_ratio(lst, ratios):\n",
    "    \"\"\"Splits a list into sublists according to given ratios.\"\"\"\n",
    "\n",
    "    random.shuffle(lst)  # Shuffle the list to ensure randomness\n",
    "\n",
    "    sublists = []\n",
    "    start = 0\n",
    "    for ratio in ratios:\n",
    "        end = start + int(len(lst) * ratio)\n",
    "        sublists.append(lst[start:end])\n",
    "        start = end\n",
    "\n",
    "    return sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e49ba673-b7f7-4cfe-9fed-71b8f0e55647",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'C:/Users/leiyi/OneDrive/Desktop/Dataset'\n",
    "output_path_gen = 'C:/Users/leiyi/OneDrive/Desktop/dataset_separated'\n",
    "output_path_list = os.listdir(output_path_gen)\n",
    "for animal_type in os.listdir(input_path):\n",
    "    image_name_list = os.listdir(os.path.join(input_path,animal_type))\n",
    "    image_name_sublists = split_list_by_ratio(image_name_list,[0.6,0.1,0.1,0.1,0.1])\n",
    "    for i in range(len(image_name_sublists)):\n",
    "        for image_name in image_name_sublists[i]:\n",
    "            shutil.copy(os.path.join(input_path,animal_type,image_name),os.path.join(output_path_gen,output_path_list[i],image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6c86a-9a3b-46a3-96d4-ab8518c1b9ef",
   "metadata": {},
   "source": [
    "Next, we perform certain actions via photoshop to process the images. We also add images of hyena and leopard into the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a0c330f-5aaf-4b04-b0e6-60b62f6a6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "leo_hye_dir = 'C:/mixed_large_bright'\n",
    "output_path = 'C:/Users/leiyi/OneDrive/Desktop/data_sep/well-illuminated'\n",
    "image_name = os.listdir(leo_hye_dir)\n",
    "image_sublist = random.choices(image_name, k = int(0.3*len(image_name)))\n",
    "for image in image_sublist:\n",
    "    shutil.copy(os.path.join(leo_hye_dir,image),os.path.join(output_path,image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d061a-ca7e-4e7f-b66c-5b3e3397ec7c",
   "metadata": {},
   "source": [
    "Rename the ones with the wrong name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268f996-844e-4577-ac9b-ca6b6c93399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(directory,newnames):\n",
    "    '''\n",
    "    take in a directory containing multiple files that need to be renamed,\n",
    "    and rename them to what is specified in a list\n",
    "    '''\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        old_path = os.path.join(directory, filename)\n",
    "        new_filename = newnames.pop(0)\n",
    "        new_path = os.path.join(directory, new_filename)\n",
    "\n",
    "        # Rename file\n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3caf647a-2ee9-4f91-a5be-bb1f3519f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'C:/Users/leiyi/OneDrive/Desktop/data_sep/grayscale'\n",
    "for filename in os.listdir(input_path):\n",
    "    if len(filename) == len('000000001977.jpg'):\n",
    "        filename_rem = filename[-8:]\n",
    "        filename_new = '9000' + filename_rem\n",
    "        old_path = os.path.join(input_path,filename)\n",
    "        new_path = os.path.join(input_path,filename_new)\n",
    "        os.rename(old_path,new_path)\n",
    "    elif len(filename) == len('000000001977.jpg') + 1:\n",
    "        filename_rem = filename[-8:]\n",
    "        filename_new = '10000' + filename_rem\n",
    "        old_path = os.path.join(input_path,filename)\n",
    "        new_path = os.path.join(input_path,filename_new)\n",
    "        os.rename(old_path,new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa843b-9833-451a-8d64-09ff7ab6d4c4",
   "metadata": {},
   "source": [
    "Now, having processed the images, we add metadata files to each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58c54045-4a7d-4e48-9e63-44a66918af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_a_metadata(images_dir):\n",
    "    '''\n",
    "    take in an image dir, and create a metadata.csv file for the images contained\n",
    "    '''\n",
    "\n",
    "    metadata = [['file_name', 'image_id','width','height','objects']]\n",
    "    with open(\"C:/Users/leiyi/OneDrive/Desktop/metadata.csv\", \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the header row (optional)\n",
    "        writer.writerow(metadata[0])\n",
    "    image_id = 0\n",
    "    transform = transforms.ToTensor()\n",
    "    for filename in os.listdir(images_dir):\n",
    "        image = Image.open(os.path.join(images_dir,filename))\n",
    "        newline = [filename]\n",
    "        objects = dict()\n",
    "        newline.append(image_id)\n",
    "        width, height = image.size\n",
    "        newline.append(width)\n",
    "        newline.append(height)\n",
    "        image_tensor = transform(image)\n",
    "        objects['pixel_values'] = image_tensor\n",
    "        objects['labels'] = ast.literal_eval(filename[:-11])\n",
    "        \n",
    "        if objects['labels'] == 0:\n",
    "            objects['category'] = 'antelope'\n",
    "        elif objects['labels'] == 1:\n",
    "            objects['category'] = 'bear'\n",
    "        elif objects['labels'] == 2:\n",
    "            objects['category'] = 'deer'\n",
    "        elif objects['labels'] == 3:\n",
    "            objects['category'] = 'fox'\n",
    "        elif objects['labels'] == 4:\n",
    "            objects['category'] = 'hare'\n",
    "        elif objects['labels'] == 5:\n",
    "            objects['category'] = 'lion'\n",
    "        elif objects['labels'] == 6:\n",
    "            objects['category'] = 'raccoon'\n",
    "        elif objects['labels'] == 7:\n",
    "            objects['category'] = 'tiger'\n",
    "        elif objects['labels'] == 8:\n",
    "            objects['category'] = 'wolf'\n",
    "        elif objects['labels'] == 9:\n",
    "            objects['category'] = 'leopard'\n",
    "        else:\n",
    "            objects['category'] = 'hyena'\n",
    "        \n",
    "        newline.append(objects)\n",
    "        \n",
    "        with open(\"C:/Users/leiyi/OneDrive/Desktop/metadata.csv\", \"a\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows([newline])\n",
    "            \n",
    "        image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f2a4983-8987-4f7c-9b22-68a0a52a95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_a_metadata('C:/Users/leiyi/OneDrive/Desktop/data_sep/well-illuminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c212c92c-4fba-4219-b646-de646a554879",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_a_metadata('C:/Users/leiyi/OneDrive/Desktop/data_sep/grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb7d8292-ea78-4522-9ba2-04d55086ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_a_metadata('C:/Users/leiyi/OneDrive/Desktop/data_sep/very dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f02220b8-bc05-46e7-8803-fac712b1da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_a_metadata('C:/Users/leiyi/OneDrive/Desktop/data_sep/less-saturated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50c08374-3219-4a39-9524-93065707c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_a_metadata('C:/Users/leiyi/OneDrive/Desktop/data_sep/underexposed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9888bf2b-7127-4a81-b4eb-56baf05d5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_a_metadata('C:/Users/leiyi/OneDrive/Desktop/datasetmixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644bcbc-cc4b-437b-9f5b-b06998dc9989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
