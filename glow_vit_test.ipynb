{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from math import floor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification, TrainingArguments, Trainer, DefaultDataCollator\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "class GlowViT(ViTForImageClassification):\n",
    "    def help():\n",
    "        print(ViTForImageClassification.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yalu_ds_list = [(\"SeaSponge/wildme10_classify\", \"glow-vit\"),\n",
    "                (\"yin30lei/wildlife_very_dark\", \"glow-vit-dark\"),\n",
    "                (\"yin30lei/wildlife_well_illuminated\", \"glow-vit-illuminate\"),\n",
    "                (\"yin30lei/wildlife_mixed\", \"glow-vit-mix\")]\n",
    "yalu_ds = yalu_ds_list[1][0]\n",
    "yalu_model_name = yalu_ds_list[1][1]\n",
    "wildlife_test_ds = load_dataset(yalu_ds, cache_dir=Path.cwd() / \"yalu_dataset\", split=\"test\" , num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '40000625.jpg', 'image_id': 1009, 'width': 640, 'height': 426, 'image': <PIL.Image.Image image mode=RGB size=640x426 at 0x1BCC2E17CA0>, 'labels': 'hare'}\n"
     ]
    }
   ],
   "source": [
    "# 11 labels for wildme10_classify\n",
    "num_labels = 11\n",
    "print(wildlife_test_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"lion\": 0, \"raccoon\": 1, \"tiger\": 2, \"wolf\": 3,\n",
    "            \"bear\": 4, \"hare\": 5, \"fox\": 6, \"deer\": 7, \n",
    "            \"leopard\" : 8, \"hyena\": 9, \"antelope\": 10}\n",
    "\n",
    "\n",
    "id2label = {v:k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93ce077b12b4a9386f95cd62d2b0852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1def34049548d59afb01043099fd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/343M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff18bf5e316f49bc969c4ee0052ecaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/325 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yalu_checkpoint = f\"SeaSponge/{yalu_model_name}\"\n",
    "model = GlowViT.from_pretrained(yalu_checkpoint,\n",
    "                cache_dir=yalu_model_name,\n",
    "                label2id=label2id,\n",
    "                id2label=id2label,\n",
    "                num_labels=num_labels,\n",
    "                attn_implementation=\"sdpa\") # no flash attention yet for ViT model\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained(yalu_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ds(examples):\n",
    "    images, labels = [], []\n",
    "    for image, label in zip(examples[\"image\"], examples[\"labels\"]):\n",
    "        pix_val = image_processor(images=image.convert(\"RGB\"), return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n",
    "        pix_val.to(device)\n",
    "        #! supposed to be a number here\n",
    "        label = label2id[label]\n",
    "        images.append(pix_val)\n",
    "        labels.append(label)\n",
    "\n",
    "    return {\"pixel_values\": images, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = wildlife_test_ds.with_transform(transform_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pixel_values': tensor([[[-0.9608, -0.9608, -0.9608,  ..., -0.9608, -0.9529, -0.9608],\n",
      "         [-0.9608, -0.9608, -0.9608,  ..., -0.9686, -0.9608, -0.9686],\n",
      "         [-0.9608, -0.9608, -0.9608,  ..., -0.9686, -0.9608, -0.9686],\n",
      "         ...,\n",
      "         [-0.9608, -0.9529, -0.9451,  ..., -0.9216, -0.9216, -0.9373],\n",
      "         [-0.9608, -0.9529, -0.9451,  ..., -0.9216, -0.9137, -0.9373],\n",
      "         [-0.9529, -0.9529, -0.9529,  ..., -0.9137, -0.9059, -0.9216]],\n",
      "\n",
      "        [[-0.9451, -0.9451, -0.9451,  ..., -0.9529, -0.9451, -0.9529],\n",
      "         [-0.9451, -0.9451, -0.9451,  ..., -0.9608, -0.9529, -0.9608],\n",
      "         [-0.9451, -0.9451, -0.9451,  ..., -0.9608, -0.9529, -0.9608],\n",
      "         ...,\n",
      "         [-0.9451, -0.9373, -0.9294,  ..., -0.9059, -0.9059, -0.9216],\n",
      "         [-0.9451, -0.9373, -0.9294,  ..., -0.9059, -0.8980, -0.9216],\n",
      "         [-0.9373, -0.9373, -0.9373,  ..., -0.8980, -0.8902, -0.9059]],\n",
      "\n",
      "        [[-0.9529, -0.9529, -0.9529,  ..., -0.9451, -0.9294, -0.9373],\n",
      "         [-0.9529, -0.9529, -0.9529,  ..., -0.9529, -0.9373, -0.9451],\n",
      "         [-0.9529, -0.9529, -0.9529,  ..., -0.9529, -0.9373, -0.9451],\n",
      "         ...,\n",
      "         [-0.9529, -0.9451, -0.9373,  ..., -0.9137, -0.9137, -0.9294],\n",
      "         [-0.9529, -0.9451, -0.9373,  ..., -0.9137, -0.9059, -0.9294],\n",
      "         [-0.9451, -0.9451, -0.9451,  ..., -0.9059, -0.8980, -0.9137]]]), 'labels': 5}\n"
     ]
    }
   ],
   "source": [
    "print(test_ds[0])\n",
    "# data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaluo\\AppData\\Local\\Temp\\ipykernel_16848\\227300765.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Define the testing arguments\n",
    "\n",
    "testing_args = TrainingArguments(\n",
    "    output_dir=yalu_model_name,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_steps=30,\n",
    "    save_total_limit=1,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "# Define the trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=testing_args,\n",
    "    # data_collator=data_collator,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=image_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yaluo\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:277: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  context_layer = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6983c0c076d2417b83f9cc1486470b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** glow-vit-dark | test... metrics *****\n",
      "  eval_loss                   =     0.5614\n",
      "  eval_model_preparation_time =      0.002\n",
      "  eval_runtime                = 0:00:09.52\n",
      "  eval_samples_per_second     =     73.675\n",
      "  eval_steps_per_second       =      4.618\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(test_ds)\n",
    "trainer.log_metrics(f\"{yalu_model_name} | test...\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
