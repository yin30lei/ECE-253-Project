{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42eb0bde-1abe-4a5b-84e4-9eb941525464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\leiyi\\anaconda3\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\leiyi\\anaconda3\\lib\\site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\leiyi\\anaconda3\\lib\\site-packages (from scikit-image) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\leiyi\\anaconda3\\lib\\site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\leiyi\\anaconda3\\lib\\site-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\leiyi\\anaconda3\\lib\\site-packages (from scikit-image) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\leiyi\\anaconda3\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\leiyi\\anaconda3\\lib\\site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\leiyi\\anaconda3\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d506443-f539-4727-8ac5-ee6bf22208a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import exposure\n",
    "from PIL import ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca376803-c36e-4257-a22c-28b8e4bfb271",
   "metadata": {},
   "source": [
    "#### Function for histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8822ec0e-8e6a-4bb3-b9bf-17e0094aa6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform histogram equalization on a single channel\n",
    "def histogram_equalization_channel(channel):\n",
    "    # Convert the channel to a numpy array\n",
    "    channel_array = np.array(channel)\n",
    "    \n",
    "    # Calculate the histogram\n",
    "    hist, bins = np.histogram(channel_array.flatten(), 256, [0, 256])\n",
    "\n",
    "    # Calculate cumulative distribution function (CDF)\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * float(hist.max()) / cdf.max()  # Normalize CDF\n",
    "\n",
    "    # Mask out all the zeros in the CDF\n",
    "    cdf_m = np.ma.masked_equal(cdf, 0)\n",
    "\n",
    "    # Perform histogram equalization by scaling the CDF\n",
    "    cdf_m = (cdf_m - cdf_m.min()) * 255 / (cdf_m.max() - cdf_m.min())  # Normalize to [0,255]\n",
    "    cdf = np.ma.filled(cdf_m, 0).astype('uint8')\n",
    "\n",
    "    # Map the original channel values to the equalized values\n",
    "    equalized_channel = cdf[channel_array]\n",
    "    return Image.fromarray(equalized_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ff1ec6-7cd7-4aa0-a873-264644b7711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization_rgb(image):\n",
    "    # Split the image into R, G, and B channels\n",
    "    r, g, b = Image.Image.split(image)\n",
    "\n",
    "    # Equalize each channel\n",
    "    r_eq = histogram_equalization_channel(r)\n",
    "    g_eq = histogram_equalization_channel(g)\n",
    "    b_eq = histogram_equalization_channel(b)\n",
    "\n",
    "    # Merge the equalized channels back together\n",
    "    equalized_image = Image.merge('RGB', (r_eq, g_eq, b_eq))\n",
    "    return equalized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80543df-0a4d-413d-bde0-c468363b63bd",
   "metadata": {},
   "source": [
    "#### Function for CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc0ab1e9-f0ae-4ae5-af8d-2dba682b9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe_im(image_dir, output_path):\n",
    "    '''\n",
    "    take in an image directory, and generate its clane version\n",
    "    and save it to the output path.\n",
    "    '''\n",
    "    # Load an RGB image using PIL\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image = Image.open(os.path.join(image_dir,image_name))\n",
    "    \n",
    "        # Convert the image to a numpy array (shape: HxWxC)\n",
    "        image_np = np.array(image)\n",
    "        \n",
    "        # Separate the RGB channels\n",
    "        r, g, b = image_np[:,:,0], image_np[:,:,1], image_np[:,:,2]\n",
    "        \n",
    "        # Apply CLAHE on each channel individually\n",
    "        r_clahe = exposure.equalize_adapthist(r, clip_limit=0.03, kernel_size=(8, 8))\n",
    "        g_clahe = exposure.equalize_adapthist(g, clip_limit=0.03, kernel_size=(8, 8))\n",
    "        b_clahe = exposure.equalize_adapthist(b, clip_limit=0.03, kernel_size=(8, 8))\n",
    "        \n",
    "        # Merge the CLAHE-processed channels back into a single image\n",
    "        clahe_image_np = np.stack([r_clahe, g_clahe, b_clahe], axis=-1)\n",
    "        \n",
    "        # Convert the processed image back to a PIL image (scaled back to 0-255 range)\n",
    "        clahe_image = Image.fromarray((clahe_image_np * 255).astype(np.uint8))\n",
    "        \n",
    "        # Save the output image\n",
    "        clahe_image.save(os.path.join(output_path,image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf4d86-2010-435a-81d9-b758aaf11db8",
   "metadata": {},
   "source": [
    "#### Creating HE pictures based on underexposed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae93260-2b47-4fcd-b7dc-7f37521da88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 55.9 s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "image_dir = 'C:/Users/leiyi/OneDrive/Desktop/data_sep/underexposed'\n",
    "image_dir_sav = 'C:/Users/leiyi/OneDrive/Desktop/data_sep_new/underexposed/he'\n",
    "for filename in os.listdir(image_dir):\n",
    "    image = Image.open(os.path.join(image_dir,filename))\n",
    "    equalized_image = histogram_equalization_rgb(image)\n",
    "    equalized_image.save(os.path.join(image_dir_sav,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda81a11-3d36-43af-bbdb-0ab1f10242e4",
   "metadata": {},
   "source": [
    "#### Creating CLAHE pictures based on underexposed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53b9df4e-08d7-48e0-959e-c8ce8fe4aac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 48s\n",
      "Wall time: 41min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output_path = 'C:/Users/leiyi/OneDrive/Desktop/data_sep_new/underexposed/clahe'\n",
    "clahe_im(image_dir,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a0ea37-e066-45e0-8ad6-6e0f8f6fcdd3",
   "metadata": {},
   "source": [
    "#### Creating HE pictures based on verydark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16228686-171c-4958-9d7d-f946bbc07c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.1 s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "image_dir = 'C:/Users/leiyi/OneDrive/Desktop/data_sep/very dark'\n",
    "image_dir_save = 'C:/Users/leiyi/OneDrive/Desktop/data_sep_new/very dark/he'\n",
    "for filename in os.listdir(image_dir):\n",
    "    image = Image.open(os.path.join(image_dir,filename))\n",
    "    equalized_image = histogram_equalization_rgb(image)\n",
    "    equalized_image.save(os.path.join(image_dir_save,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03194467-d1a1-49f2-ac4a-4b0f15a1863f",
   "metadata": {},
   "source": [
    "#### Creating CLAHE pictures for very dark images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcc1333b-60ad-482e-ae78-b129a60c4e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25min 31s\n",
      "Wall time: 57min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output_path = 'C:/Users/leiyi/OneDrive/Desktop/data_sep_new/very dark/clahe'\n",
    "clahe_im(image_dir,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8cf24-54df-4a53-9df4-d676011aa856",
   "metadata": {},
   "source": [
    "#### Creating HE pictures for less-saturated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3bbe55d-691c-4d52-88f5-4cc13bab17b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 51.8 s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "image_dir = 'C:/Users/leiyi/OneDrive/Desktop/data_sep/less-saturated'\n",
    "image_dir_save = 'C:/Users/leiyi/OneDrive/Desktop/data_sep_new/less-saturated/he'\n",
    "for filename in os.listdir(image_dir):\n",
    "    image = Image.open(os.path.join(image_dir,filename))\n",
    "    equalized_image = histogram_equalization_rgb(image)\n",
    "    equalized_image.save(os.path.join(image_dir_save,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5a5a3-d865-49f6-b87d-6c1a53143c7c",
   "metadata": {},
   "source": [
    "#### Creating CLAHE pictures for less-saturated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aae3b53d-59ec-4298-b6a1-e7d0b59bfe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17min 13s\n",
      "Wall time: 55min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output_path = 'C:/Users/leiyi/OneDrive/Desktop/data_sep_new/less-saturated/clahe'\n",
    "clahe_im(image_dir,output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
